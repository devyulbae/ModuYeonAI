{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devyulbae/AIClass/blob/main/5_Data_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa3571cc",
      "metadata": {
        "id": "aa3571cc"
      },
      "source": [
        "## Use case\n",
        "\n",
        "합성 데이터는 실제 이벤트에서 수집된 데이터가 아닌 인위적으로 생성된 데이터입니다. 개인 정보를 침해하거나 현실적인 제약에 부딪히지 않고 실제 데이터를 시뮬레이션하는 데 사용됩니다.\n",
        "\n",
        "합성 데이터의 이점:\n",
        "\n",
        "1. **Privacy and Security**:실제 개인 데이터가 유출될 위험이 없습니다.\n",
        "2. **Data Augmentation**: 머신러닝을 위한 데이터 세트 확장.\n",
        "3. **Flexibility**: 특정 또는 희귀한 시나리오를 생성합니다.\n",
        "4. **Cost-effective**: 실제 데이터 수집보다 저렴한 경우가 많습니다.\n",
        "5. **Regulatory Compliance**: 엄격한 데이터 보호법을 준수하는 데 도움이 됩니다.\n",
        "6. **Model Robustness**: AI 모델을 더 잘 일반화할 수 있습니다.\n",
        "7. **Rapid Prototyping**: 실제 데이터 없이도 빠르게 테스트할 수 있습니다.\n",
        "8. **Controlled Experimentation**: 특정 조건을 시뮬레이션합니다.\n",
        "9. **Access to Data**: 실제 데이터를 사용할 수 없는 경우의 대안.\n",
        "\n",
        "참고: 이러한 장점에도 불구하고 합성 데이터는 실제 세계의 복잡성을 항상 포착하지 못할 수 있으므로 신중하게 사용해야 합니다.\n",
        "\n",
        "## Quickstart\n",
        "\n",
        "이 노트북에서는 랭체인 라이브러리를 사용해 합성 의료 청구 기록을 생성하는 방법을 자세히 살펴보겠습니다. 이 도구는 알고리즘을 개발하거나 테스트하고 싶지만 개인정보 보호 문제나 데이터 가용성 문제로 인해 실제 환자 데이터를 사용하고 싶지 않을 때 특히 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bca57012",
      "metadata": {
        "id": "bca57012"
      },
      "source": [
        "### Setup\n",
        "\n",
        "먼저, 종속 요소와 함께 랭체인 라이브러리가 설치되어 있어야 합니다. OpenAI 제너레이터 체인을 사용하므로 이 라이브러리도 함께 설치합니다. 이 라이브러리는 실험용 라이브러리이므로 설치 시 `langchain_experimental`을 포함시켜야 합니다. 그런 다음 필요한 모듈을 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0377478",
      "metadata": {
        "id": "a0377478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0979e92a-f95e-4c21-e27f-01ed2668c8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.45-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-core<0.1,>=0.0.12 (from langchain)\n",
            "  Downloading langchain_core-0.0.12-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, langsmith, jsonpatch, httpcore, langchain-core, httpx, dataclasses-json, openai, langchain, langchain_experimental\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.3 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.348 langchain-core-0.0.12 langchain_experimental-0.0.45 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.3.7 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain_experimental openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx2pVeYdOhk6",
        "outputId": "63fff47b-0a36-4a26-ab43-c72a2ba77f61"
      },
      "id": "cx2pVeYdOhk6",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "from langchain_experimental.tabular_synthetic_data.openai import (\n",
        "    OPENAI_TEMPLATE,\n",
        "    create_openai_data_generator,\n",
        ")\n",
        "from langchain_experimental.tabular_synthetic_data.prompts import (\n",
        "    SYNTHETIC_FEW_SHOT_PREFIX,\n",
        "    SYNTHETIC_FEW_SHOT_SUFFIX,\n",
        ")"
      ],
      "metadata": {
        "id": "AspqleqsOfbc"
      },
      "id": "AspqleqsOfbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_TEMPLATE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCBrrZr4J4jC",
        "outputId": "96268d0f-a168-40bc-b4cc-15564e6c9886"
      },
      "id": "LCBrrZr4J4jC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['example'], template='{example}')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYNTHETIC_FEW_SHOT_PREFIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E-6uzfNGHGUl",
        "outputId": "c8e11f86-635b-43dd-fc15-91ce4f526c51"
      },
      "id": "E-6uzfNGHGUl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a test about generating synthetic data about {subject}. Examples below:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYNTHETIC_FEW_SHOT_SUFFIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wUPdXXqcHUv-",
        "outputId": "26239334-fd83-4dde-b586-9ffbf3f2be6a"
      },
      "id": "wUPdXXqcHUv-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Now you generate synthetic data about {subject}. Make sure to {extra}:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a0917b",
      "metadata": {
        "id": "a5a0917b"
      },
      "source": [
        "## 1. Define Your Data Model\n",
        "모든 데이터 세트에는 구조 또는 \"스키마\"가 있습니다. 아래의 MedicalBilling 클래스는 합성 데이터에 대한 스키마 역할을 합니다. 이를 정의함으로써 합성 데이터 생성기에 예상되는 데이터의 형태와 특성을 알려줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291bad6e",
      "metadata": {
        "id": "291bad6e"
      },
      "outputs": [],
      "source": [
        "class MedicalBilling(BaseModel):\n",
        "    patient_id: int\n",
        "    patient_name: str\n",
        "    diagnosis_code: str\n",
        "    procedure_code: str\n",
        "    total_charge: float\n",
        "    insurance_claim_amount: float"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2059ca63",
      "metadata": {
        "id": "2059ca63"
      },
      "source": [
        "예를 들어, 모든 레코드에는 정수인 'patient_id'와 문자열인 'patient_name' 등이 있습니다.\n",
        "\n",
        "## 2. Sample Data\n",
        "합성 데이터 생성기를 안내하기 위해 실제와 유사한 몇 가지 예시를 제공하는 것이 유용합니다. 이러한 예는 원하는 데이터의 종류를 대표하는 '시드' 역할을 하며, 생성기는 이를 사용하여 유사한 데이터를 더 많이 생성할 수 있습니다.\n",
        "\n",
        "다음은 몇 가지 가상의 의료비 청구 기록입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b989b792",
      "metadata": {
        "id": "b989b792"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"example\": \"\"\"Patient ID: 123456, Patient Name: John Doe, Diagnosis Code:\n",
        "        J20.9, Procedure Code: 99203, Total Charge: $500, Insurance Claim Amount: $350\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"example\": \"\"\"Patient ID: 789012, Patient Name: Johnson Smith, Diagnosis\n",
        "        Code: M54.5, Procedure Code: 99213, Total Charge: $150, Insurance Claim Amount: $120\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"example\": \"\"\"Patient ID: 345678, Patient Name: Emily Stone, Diagnosis Code:\n",
        "        E11.9, Procedure Code: 99214, Total Charge: $300, Insurance Claim Amount: $250\"\"\"\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e28809",
      "metadata": {
        "id": "57e28809"
      },
      "source": [
        "## 3. Craft a Prompt Template\n",
        "\n",
        "생성기는 데이터를 생성하는 방법을 알지 못하므로 우리가 안내해야 합니다. 이를 위해 프롬프트 템플릿을 생성합니다.\n",
        "이 템플릿은 기본 언어 모델에 원하는 형식의 합성 데이터를 생성하는 방법을 안내하는 데 도움이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea6e042e",
      "metadata": {
        "id": "ea6e042e"
      },
      "outputs": [],
      "source": [
        "OPENAI_TEMPLATE = PromptTemplate(input_variables=[\"example\"], template=\"{example}\")\n",
        "\n",
        "prompt_template = FewShotPromptTemplate(\n",
        "    prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
        "    examples=examples, # 가상데이터를 첨부해줍니다.\n",
        "    suffix=SYNTHETIC_FEW_SHOT_SUFFIX,\n",
        "    input_variables=[\"subject\", \"extra\"],\n",
        "    example_prompt=OPENAI_TEMPLATE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa6da3cb",
      "metadata": {
        "id": "fa6da3cb"
      },
      "source": [
        "`FewShotPromptTemplate` 에는 다음이 포함됩니다::\n",
        "\n",
        "- `prefix` and `suffix`: 여기에는 안내 문맥이나 지침이 포함되어 있을 가능성이 높습니다.\n",
        "- `examples`: 앞서 정의한 샘플 데이터입니다.\n",
        "- `input_variables`: 이러한 변수(\"subject\", \"extra\")는 나중에 동적으로 채울 수 있는 자리 표시자입니다. 예를 들어, \"subject\"는 모델을 더 자세히 안내하기 위해 \"medical_billing\"으로 채워질 수 있습니다.\n",
        "- `example_prompt`: 이 프롬프트 템플릿은 프롬프트에서 각 예제 행이 취할 형식입니다.\n",
        "\n",
        "## 4. Creating the Data Generator\n",
        "\n",
        "스키마와 프롬프트가 준비되었으면 다음 단계는 데이터 생성기를 만드는 것입니다. 이 객체는 합성 데이터를 얻기 위해 기본 언어 모델과 통신하는 방법을 알고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b9ba911",
      "metadata": {
        "id": "1b9ba911"
      },
      "outputs": [],
      "source": [
        "synthetic_data_generator = create_openai_data_generator(\n",
        "    output_schema=MedicalBilling,\n",
        "    llm=ChatOpenAI(\n",
        "        temperature=1\n",
        "    ),  # You'll need to replace with your actual Language Model instance\n",
        "    prompt=prompt_template,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4198bd6",
      "metadata": {
        "id": "a4198bd6"
      },
      "source": [
        "## 5. Generate Synthetic Data\n",
        "마지막으로 합성 데이터를 가져와 보겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a424c890",
      "metadata": {
        "id": "a424c890"
      },
      "outputs": [],
      "source": [
        "synthetic_results = synthetic_data_generator.generate(\n",
        "    subject=\"medical_billing\",\n",
        "    extra=\"the name must be chosen at random. Make it something you wouldn't normally choose.\",\n",
        "    runs=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trfkk6xVHdt8",
        "outputId": "21063411-d9bf-4781-dd21-f0da3cf76823"
      },
      "id": "Trfkk6xVHdt8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[MedicalBilling(patient_id=987654, patient_name='Jennifer Parker', diagnosis_code='C50.9', procedure_code='99204', total_charge=400.0, insurance_claim_amount=320.0),\n",
              " MedicalBilling(patient_id=123456, patient_name='Sophia Johnson', diagnosis_code='A09.9', procedure_code='99205', total_charge=500.0, insurance_claim_amount=400.0),\n",
              " MedicalBilling(patient_id=543210, patient_name='Oliver Wilson', diagnosis_code='G20.9', procedure_code='99213', total_charge=250.0, insurance_claim_amount=200.0),\n",
              " MedicalBilling(patient_id=789012, patient_name='Xavier Rodriguez', diagnosis_code='F32.9', procedure_code='99214', total_charge=350.0, insurance_claim_amount=280.0),\n",
              " MedicalBilling(patient_id=987654, patient_name='Amelia Thompson', diagnosis_code='R07.9', procedure_code='99204', total_charge=400.0, insurance_claim_amount=320.0),\n",
              " MedicalBilling(patient_id=123456, patient_name='Elijah Parker', diagnosis_code='A09.9', procedure_code='99215', total_charge=300.0, insurance_claim_amount=240.0),\n",
              " MedicalBilling(patient_id=456789, patient_name='Olivia Johnson', diagnosis_code='G44.1', procedure_code='99213', total_charge=250.0, insurance_claim_amount=200.0),\n",
              " MedicalBilling(patient_id=987654, patient_name='Isabella Rodriguez', diagnosis_code='S62.309A', procedure_code='99203', total_charge=350.0, insurance_claim_amount=280.0),\n",
              " MedicalBilling(patient_id=246813, patient_name='Liam Thompson', diagnosis_code='F41.1', procedure_code='99214', total_charge=275.0, insurance_claim_amount=220.0),\n",
              " MedicalBilling(patient_id=123456, patient_name='Sophia Smith', diagnosis_code='M25.511', procedure_code='99212', total_charge=200.0, insurance_claim_amount=150.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa4402e9",
      "metadata": {
        "id": "fa4402e9"
      },
      "source": [
        "이 명령은 생성기에 10개의 합성 의료 청구 기록을 생성하도록 요청합니다. 결과는 `synthetic_results`에 저장됩니다. 출력은 MedicalBilling 파이던트 모델 목록입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a4cbf9",
      "metadata": {
        "id": "53a4cbf9"
      },
      "source": [
        "### Other implementations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e715d94",
      "metadata": {
        "scrolled": true,
        "id": "9e715d94"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_experimental.synthetic_data import (\n",
        "    DatasetGenerator,\n",
        "    create_data_generation_chain,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94fccedd",
      "metadata": {
        "scrolled": true,
        "id": "94fccedd"
      },
      "outputs": [],
      "source": [
        "# LLM\n",
        "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "chain = create_data_generation_chain(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4314c3ea",
      "metadata": {
        "id": "4314c3ea",
        "outputId": "7b94fd7f-1515-463d-c1b1-983e4ca6cc49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fields': ['blue', 'yellow'],\n",
              " 'preferences': {},\n",
              " 'text': 'The vibrant blue sky contrasted beautifully with the golden yellow sunflowers, creating a mesmerizing scene that seemed to capture the essence of a perfect summer day.'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "chain({\"fields\": [\"blue\", \"yellow\"], \"preferences\": {}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b116c487",
      "metadata": {
        "id": "b116c487",
        "outputId": "5c41057e-285f-48c5-d5b0-54ca8d5aa9ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fields': {'colors': ['blue', 'yellow']},\n",
              " 'preferences': {'style': 'Make it in a style of a weather forecast.'},\n",
              " 'text': \"In today's weather forecast, we can expect a vibrant display of colors with a stunning blend of blue and yellow, reminiscent of a picturesque sunset on a summer evening.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "chain(\n",
        "    {\n",
        "        \"fields\": {\"colors\": [\"blue\", \"yellow\"]},\n",
        "        \"preferences\": {\"style\": \"Make it in a style of a weather forecast.\"},\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff823394",
      "metadata": {
        "id": "ff823394",
        "outputId": "c7456c44-b070-4a24-9ea6-f6fe92029566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fields': {'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
              " 'preferences': None,\n",
              " 'text': 'Tom Hanks, a legendary actor known for his exceptional talent, has graced the silver screen with his remarkable performances in movies such as \"Forrest Gump\" and \"Green Mile\", captivating audiences worldwide with his versatility and magnetic presence.'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "chain(\n",
        "    {\n",
        "        \"fields\": {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
        "        \"preferences\": None,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ea1ad5b",
      "metadata": {
        "scrolled": true,
        "id": "1ea1ad5b",
        "outputId": "504e51b1-2b21-4cf6-99e7-2fe481a36ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fields': [{'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
              "  {'actor': 'Mads Mikkelsen', 'movies': ['Hannibal', 'Another round']}],\n",
              " 'preferences': {'minimum_length': 200, 'style': 'gossip'},\n",
              " 'text': 'In a surprising turn of events, the illustrious Hollywood actor Tom Hanks, renowned for his exceptional performances in iconic movies such as \"Forrest Gump\" and \"Green Mile,\" shares the limelight with the enigmatic Mads Mikkelsen, known for his captivating portrayal of the infamous Hannibal Lecter in the thrilling television series and his recent triumph in the critically acclaimed film \"Another round.\" These two incredible actors, each with their own unique style and mesmerizing screen presence, have captured the hearts of audiences worldwide, cementing their status as true legends in the realm of cinema.'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "chain(\n",
        "    {\n",
        "        \"fields\": [\n",
        "            {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
        "            {\"actor\": \"Mads Mikkelsen\", \"movies\": [\"Hannibal\", \"Another round\"]},\n",
        "        ],\n",
        "        \"preferences\": {\"minimum_length\": 200, \"style\": \"gossip\"},\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93c7a4bb",
      "metadata": {
        "id": "93c7a4bb"
      },
      "source": [
        "보시다시피 제작된 예시들은 다양하고 우리가 원하는 정보를 담고 있습니다. 또한 스타일도 주어진 선호도를 잘 반영하고 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f7f55a",
      "metadata": {
        "id": "75f7f55a"
      },
      "source": [
        "## Generating exemplary dataset for extraction benchmarking purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e98bc4",
      "metadata": {
        "id": "94e98bc4"
      },
      "outputs": [],
      "source": [
        "inp = [\n",
        "    {\n",
        "        \"Actor\": \"Tom Hanks\",\n",
        "        \"Film\": [\n",
        "            \"Forrest Gump\",\n",
        "            \"Saving Private Ryan\",\n",
        "            \"The Green Mile\",\n",
        "            \"Toy Story\",\n",
        "            \"Catch Me If You Can\",\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"Actor\": \"Tom Hardy\",\n",
        "        \"Film\": [\n",
        "            \"Inception\",\n",
        "            \"The Dark Knight Rises\",\n",
        "            \"Mad Max: Fury Road\",\n",
        "            \"The Revenant\",\n",
        "            \"Dunkirk\",\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "generator = DatasetGenerator(model, {\"style\": \"informal\", \"minimal length\": 500})\n",
        "dataset = generator(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "478eaca4",
      "metadata": {
        "id": "478eaca4",
        "outputId": "efd7d1a9-cc56-44af-d779-74ea1e314f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'fields': {'Actor': 'Tom Hanks',\n",
              "   'Film': ['Forrest Gump',\n",
              "    'Saving Private Ryan',\n",
              "    'The Green Mile',\n",
              "    'Toy Story',\n",
              "    'Catch Me If You Can']},\n",
              "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
              "  'text': 'Tom Hanks, the beloved actor known for his roles in iconic films such as \"Forrest Gump,\" \"Saving Private Ryan,\" \"The Green Mile,\" \"Toy Story,\" and \"Catch Me If You Can,\" effortlessly captivates audiences with his unmatched talent and versatility. Whether he is running across the country as the endearing Forrest Gump or tugging at our heartstrings as the compassionate prison guard in \"The Green Mile,\" Hanks consistently delivers performances that leave a lasting impact. With his charming demeanor and incredible acting skills, it is no wonder that Tom Hanks has become a household name and a true legend in the film industry.'},\n",
              " {'fields': {'Actor': 'Tom Hardy',\n",
              "   'Film': ['Inception',\n",
              "    'The Dark Knight Rises',\n",
              "    'Mad Max: Fury Road',\n",
              "    'The Revenant',\n",
              "    'Dunkirk']},\n",
              "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
              "  'text': 'Tom Hardy, the versatile actor known for his roles in films such as \"Inception,\" \"The Dark Knight Rises,\" \"Mad Max: Fury Road,\" \"The Revenant,\" and \"Dunkirk,\" captivates audiences with his raw talent, effortlessly transitioning between complex characters and showcasing his ability to immerse himself in diverse roles across various genres. From his charismatic portrayal of the enigmatic Eames in the mind-bending thriller \"Inception\" to his intense and physically demanding performance as the formidable Bane in Christopher Nolan\\'s \"The Dark Knight Rises,\" Hardy\\'s on-screen presence is nothing short of mesmerizing. In \"Mad Max: Fury Road,\" he embodies the iconic character of Max Rockatansky, delivering a gritty and riveting performance that perfectly captures the essence of the post-apocalyptic world. His portrayal of the treacherous John Fitzgerald in \"The Revenant\" showcases his ability to portray morally complex characters with depth and nuance. Lastly, in \"Dunkirk,\" Hardy\\'s portrayal of Farrier, a courageous RAF pilot, exemplifies his dedication to his craft as he flawlessly conveys the bravery, resilience, and unwavering determination of a hero amidst the chaos of war. With each film, Tom Hardy continues to push the boundaries of his craft, leaving a lasting impact on the cinematic world and solidifying his status as one of the most talented actors of his generation.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293a7d64",
      "metadata": {
        "id": "293a7d64"
      },
      "source": [
        "## Extraction from generated examples\n",
        "이제 이렇게 생성된 데이터에서 출력을 추출할 수 있는지, 그리고 우리의 사례와 어떻게 비교되는지 살펴봅시다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03c6a375",
      "metadata": {
        "id": "03c6a375"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.chains import create_extraction_chain_pydantic\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9461d225",
      "metadata": {
        "id": "9461d225"
      },
      "outputs": [],
      "source": [
        "class Actor(BaseModel):\n",
        "    Actor: str = Field(description=\"name of an actor\")\n",
        "    Film: List[str] = Field(description=\"list of names of films they starred in\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8390171d",
      "metadata": {
        "id": "8390171d"
      },
      "source": [
        "### Parsers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a5528d2",
      "metadata": {
        "id": "8a5528d2",
        "outputId": "415b6b85-a1ca-411f-d752-f06de82e0a72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Actor(Actor='Tom Hanks', Film=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Toy Story', 'Catch Me If You Can'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "llm = OpenAI()\n",
        "parser = PydanticOutputParser(pydantic_object=Actor)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Extract fields from a given text.\\n{format_instructions}\\n{text}\\n\",\n",
        "    input_variables=[\"text\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "_input = prompt.format_prompt(text=dataset[0][\"text\"])\n",
        "output = llm(_input.to_string())\n",
        "\n",
        "parsed = parser.parse(output)\n",
        "parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "926a7eed",
      "metadata": {
        "id": "926a7eed",
        "outputId": "1fe4369b-b059-47a0-8ad5-39c0b1c7833f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "(parsed.Actor == inp[0][\"Actor\"]) & (parsed.Film == inp[0][\"Film\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b00f0b87",
      "metadata": {
        "id": "b00f0b87"
      },
      "source": [
        "### Extractors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "523bb584",
      "metadata": {
        "id": "523bb584",
        "outputId": "3b768e1a-0b40-4ffe-e447-c08f7ac05ee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Actor(Actor='Tom Hardy', Film=['Inception', 'The Dark Knight Rises', 'Mad Max: Fury Road', 'The Revenant', 'Dunkirk'])]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "extractor = create_extraction_chain_pydantic(pydantic_schema=Actor, llm=model)\n",
        "extracted = extractor.run(dataset[1][\"text\"])\n",
        "extracted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8451c2b",
      "metadata": {
        "id": "f8451c2b",
        "outputId": "c32078df-e420-4e4e-a2f2-914cb6eee34e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "(extracted[0].Actor == inp[1][\"Actor\"]) & (extracted[0].Film == inp[1][\"Film\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b03de4d",
      "metadata": {
        "id": "0b03de4d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}